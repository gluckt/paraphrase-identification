{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ed2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c0c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How the metaphors we use to describe discovery affect men and women in the sciences', 'Light Bulbs or Seeds ? How Metaphors for Ideas Influence Judgments About Genius']\n"
     ]
    }
   ],
   "source": [
    "def text_split():\n",
    "    #filename = sys.argv[1]\n",
    "    filename = 'Twitter_URL_Corpus_train.txt'\n",
    "    file = open(filename, encoding='utf-8')\n",
    "    lines = file.readlines()\n",
    "    count = 0\n",
    "    raw = []\n",
    "    #raw1 = []\n",
    "    #raw2 = []\n",
    "    label = []\n",
    "    # Strips the newline character\n",
    "    for line in lines:\n",
    "        tokens = line.split('\\t')\n",
    "        if int(tokens[2][1]) !=3:\n",
    "            raw.append([tokens[0].strip(), tokens[1].strip()])\n",
    "            if int(tokens[2][1]) <= 2:  \n",
    "                label.append(0)  \n",
    "            else:\n",
    "                label.append(1)  \n",
    "#         if int(tokens[2][1]) !=3:\n",
    "#             raw1.append(tokens[0].strip())\n",
    "#             raw2.append(tokens[1])\n",
    "#             if int(tokens[2][1]) <= 2:  \n",
    "#                 label.append('False')  \n",
    "#             else:\n",
    "#                 label.append('True')  \n",
    "           \n",
    "        count += 1\n",
    "       \n",
    "    return raw, label \n",
    "#text_split()\n",
    "train, train_label=text_split()\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1168d1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 13], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def word2index(input_list):\n",
    "    encoded_list=[]\n",
    "    for sentence_list in input_list:\n",
    "        vec_list=[]\n",
    "        for sentences in sentence_list:\n",
    "            words = sentences.split(' ')\n",
    "        \n",
    "            vocab = Counter(words) \n",
    "            vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "            vocab_size = len(vocab)\n",
    "        \n",
    "            word2idx = {word: ind for ind, word in enumerate(vocab)} \n",
    "        \n",
    "            encoded_sentences = [word2idx[word] for word in words]\n",
    "            vec_list.append(encoded_sentences)\n",
    "        encoded_list.append(vec_list)\n",
    "    return encoded_list\n",
    "encoded_train=word2index(train)\n",
    "#encoded_train_2=word2index(train_2)\n",
    "\n",
    "print(encoded_train[0])\n",
    "#encoded_train.shape\n",
    "#print(encoded_train_2[0])\n",
    "#print(encoded_train_2[1])\n",
    "\n",
    "# emb_dim = 3 \n",
    "# emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "# word_vectors = emb_layer(torch.LongTensor(encoded_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff86a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Vocabulary Words:  48361\n"
     ]
    }
   ],
   "source": [
    "class Language:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words + 1\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words + 1] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "language = Language()\n",
    "for data in [train]:\n",
    "    for question_pair in data:\n",
    "#         print(question_pair)\n",
    "        q1 = question_pair[0]\n",
    "        q2 = question_pair[1]\n",
    "        language.addSentence(q1)\n",
    "        language.addSentence(q2)\n",
    "# print(language.word2index)\n",
    "n_vocabulary_words = len(language.word2index)\n",
    "print ('Total Unique Vocabulary Words: ', n_vocabulary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54866d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 2, 14], [170, 240, 1591, 5308, 1070, 8069, 6, 59, 60, 2, 1253, 151, 172, 40688, 43579, 93, 3138, 736, 6, 172, 29430, 11, 43580, 11, 6, 555, 4, 43581, 2388, 117, 172, 43582], 0))\n"
     ]
    }
   ],
   "source": [
    "class QuestionsDataset(Dataset):\n",
    "    def __init__(self, questions_list, word2index, labels):\n",
    "        self.questions_list = questions_list\n",
    "        self.labels = labels\n",
    "        self.word2index = word2index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        questions_pair = self.questions_list[index]\n",
    "        q1 = questions_pair[0]\n",
    "        q1_indices = []\n",
    "        for word in q1.split():\n",
    "            q1_indices.append(self.word2index[word])\n",
    "            \n",
    "        q2 = question_pair[1]\n",
    "        q2_indices = []\n",
    "        for word in q2.split():\n",
    "            q2_indices.append(self.word2index[word])\n",
    "            \n",
    "        # q1_indices and q2_indices are lists of indices against words used in the sentence \n",
    "        return q1_indices, q2_indices, self.labels[index]\n",
    "    \n",
    "train_dataset = QuestionsDataset(train, language.word2index, train_label)\n",
    "print(next(enumerate(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c44ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCollate:\n",
    "    def custom_collate(self, batch):\n",
    "\n",
    "        # batch = list of tuples where each tuple is of the form ([i1, i2, i3], [j1, j2, j3], label)\n",
    "        q1_list = []\n",
    "        q2_list = []\n",
    "        labels = []\n",
    "        for training_example in batch:\n",
    "#             print(batch)\n",
    "            q1_list.append(training_example[0])\n",
    "            q2_list.append(training_example[1])\n",
    "            labels.append(training_example[2])\n",
    "          \n",
    "        \n",
    "        q1_lengths = [len(q) for q in q1_list]\n",
    "        q2_lengths = [len(q) for q in q2_list]\n",
    "        \n",
    "        return q1_list, q1_lengths, q2_list, q2_lengths, labels\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return self.custom_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bb5c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ([[444, 199, 10137, 238, 472, 12979, 11, 238, 155, 7579, 472, 12979, 322]], [13], [[170, 240, 1591, 5308, 1070, 8069, 6, 59, 60, 2, 1253, 151, 172, 40688, 43579, 93, 3138, 736, 6, 172, 29430, 11, 43580, 11, 6, 555, 4, 43581, 2388, 117, 172, 43582]], [32], [0])\n",
      "Training Set Size 33760, Validation Set Size 8440\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.2\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "shuffle_dataset = True\n",
    "random_seed = 32\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# print(train_indices)\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "# print(next(enumerate(train_sampler)))\n",
    "validation_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, sampler=train_sampler, collate_fn=CustomCollate())\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, sampler=validation_sampler, collate_fn=CustomCollate())\n",
    "\n",
    "for i, (q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths, labels) in enumerate(train_loader):\n",
    "    print(i, (q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths, labels))\n",
    "    break\n",
    "print ('Training Set Size {}, Validation Set Size {}'.format(len(train_indices), len(val_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9102d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.KeyedVectors object at 0x000001FE130A6048>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "C:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:189.)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_PATH = './GoogleNews-vectors-negative300.bin'\n",
    "EMBEDDING_DIMENSION = 300\n",
    "# Load pre-trained embeddings from word2vec\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(EMBEDDING_PATH, binary=True)\n",
    "print(word2vec_model)\n",
    "# Convert word2vec embeddings into FloatTensor\n",
    "word2vec_weights = torch.FloatTensor(word2vec_model.vectors)\n",
    "\n",
    "# Create a random weight tensor of the shape (n_vocabulary_words + 1, EMBEDDING_DIMENSION) and place each word's embedding from word2vec at the index assigned to that word\n",
    "# Two key points:\n",
    "# 1. Weights tensor has been initialized randomly so that the words which are part of our dataset vocabulary but are not present in word2vec are given a random embedding\n",
    "# 2. Embedding at 0 index is all zeros. This is the embedding for the padding that we will do for batch processing\n",
    "weights = torch.randn(n_vocabulary_words + 1, EMBEDDING_DIMENSION)\n",
    "weights[0] = torch.zeros(EMBEDDING_DIMENSION)\n",
    "for word, lang_word_index in language.word2index.items():\n",
    "    if word in word2vec_model:\n",
    "        weights[lang_word_index] = torch.FloatTensor(word2vec_model.word_vec(word))\n",
    "\n",
    "# del word2vec_model\n",
    "# del word2vec_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3154977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "How 1\n",
      "torch.Size([300])\n",
      "tensor([ 0.1602,  0.2168,  0.0549,  0.2070, -0.1533,  0.1338,  0.1069,  0.0183,\n",
      "         0.1406, -0.1025,  0.1797, -0.1445, -0.3457, -0.0703, -0.2598,  0.2168,\n",
      "         0.0771,  0.1973,  0.0537, -0.0430, -0.0322,  0.0317,  0.4688, -0.1963,\n",
      "        -0.1484,  0.1357, -0.2305, -0.0679,  0.1245,  0.0845,  0.0835,  0.0598,\n",
      "        -0.0352, -0.1709,  0.0253,  0.3750, -0.0084,  0.0898, -0.0396,  0.2793,\n",
      "        -0.1660,  0.0060,  0.1318, -0.2812, -0.0352,  0.0038, -0.0197, -0.0786,\n",
      "         0.0640,  0.2637, -0.3027,  0.2158,  0.0366, -0.1826,  0.1494, -0.0525,\n",
      "        -0.2100,  0.0496,  0.3066,  0.1348,  0.1572,  0.0060, -0.4453, -0.0347,\n",
      "        -0.0332, -0.2334,  0.0007,  0.2236, -0.1001, -0.1992,  0.1309,  0.1748,\n",
      "         0.1816,  0.0154, -0.1572, -0.4023, -0.0464,  0.2236, -0.0317,  0.2227,\n",
      "        -0.1504,  0.0859, -0.1699,  0.1196, -0.4863, -0.2109, -0.1777,  0.1836,\n",
      "        -0.0320,  0.2246, -0.0781,  0.1406, -0.3574,  0.0164, -0.0771, -0.0806,\n",
      "         0.2070, -0.0052,  0.0106,  0.1758,  0.2021,  0.0071, -0.0835,  0.1079,\n",
      "        -0.2031, -0.0203, -0.3262, -0.0771, -0.1084,  0.1797, -0.1230, -0.0090,\n",
      "         0.0684, -0.0815,  0.4062,  0.0264, -0.1250,  0.1416, -0.1318,  0.0483,\n",
      "        -0.1543,  0.0483,  0.0118, -0.0664,  0.1396,  0.1885, -0.1670,  0.2051,\n",
      "        -0.0457, -0.2910, -0.0513, -0.1973, -0.0077, -0.0713,  0.0147, -0.3047,\n",
      "        -0.0344, -0.2227, -0.0095,  0.2041,  0.2441, -0.0237, -0.0894, -0.0254,\n",
      "         0.2559, -0.2988,  0.3145, -0.3770,  0.3184,  0.0347,  0.0032, -0.0212,\n",
      "         0.0293,  0.0557,  0.1611, -0.0762, -0.0845, -0.0233, -0.0869, -0.1001,\n",
      "        -0.0022,  0.1719,  0.0549,  0.0752,  0.0299, -0.0151,  0.1514, -0.1318,\n",
      "        -0.1504,  0.2500, -0.1855,  0.2256, -0.0369, -0.2217, -0.1973,  0.1060,\n",
      "         0.1914,  0.0132, -0.1406, -0.1260, -0.1836,  0.0123,  0.0189, -0.1328,\n",
      "        -0.0825,  0.1523, -0.1533, -0.0139,  0.1455,  0.0396,  0.0391, -0.1729,\n",
      "         0.1582, -0.0603,  0.0503, -0.2754, -0.1099, -0.0056,  0.2656, -0.2139,\n",
      "         0.0703,  0.2070, -0.2949,  0.2910, -0.0781,  0.0601, -0.1973, -0.0007,\n",
      "        -0.0962, -0.0640, -0.2012,  0.2207, -0.0669, -0.0417, -0.2969,  0.0150,\n",
      "         0.2275,  0.2432, -0.0225, -0.0176, -0.1562, -0.0654, -0.4258, -0.0106,\n",
      "         0.1089, -0.1338,  0.1348, -0.2480, -0.0145, -0.1514,  0.1865, -0.0481,\n",
      "         0.0420,  0.0208, -0.0527, -0.1846, -0.0237,  0.0947, -0.1406,  0.0287,\n",
      "        -0.1108,  0.0981,  0.2090, -0.2793, -0.2812, -0.1211,  0.0201,  0.0718,\n",
      "         0.0223, -0.0439,  0.2754,  0.1953,  0.3418,  0.3770,  0.0364, -0.2676,\n",
      "        -0.0055, -0.0503, -0.0566,  0.0057, -0.0503,  0.0981, -0.2041,  0.0698,\n",
      "        -0.0840,  0.1768,  0.0354,  0.0464, -0.0630,  0.0308, -0.1069,  0.1709,\n",
      "         0.2852,  0.1992, -0.1699, -0.1357, -0.0188, -0.1250,  0.0452,  0.1396,\n",
      "         0.2617,  0.0491, -0.0718,  0.4531,  0.0184, -0.1924, -0.3594, -0.2021,\n",
      "        -0.0325,  0.3965, -0.1348,  0.0972, -0.1187, -0.0200, -0.0947, -0.4180,\n",
      "         0.0669,  0.0454, -0.0811,  0.0894])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  \"\"\"\n",
      "C:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMENSION = 300\n",
    "test_weights = torch.randn(n_vocabulary_words + 1, EMBEDDING_DIMENSION)\n",
    "for word, lang_word_index in language.word2index.items():\n",
    "    if word in word2vec_model:\n",
    "        test_weights[lang_word_index] = torch.FloatTensor(word2vec_model.word_vec(word))\n",
    "        print(len(word2vec_model.word_vec(word)))\n",
    "        print(word, lang_word_index)\n",
    "        print(test_weights[1].size())\n",
    "        print(test_weights[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834b6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NLPModel(nn.Module):\n",
    "\n",
    "#     def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "#         super(NLPModel, self).__init__()\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "#         self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         embeds = self.embeddings(inputs).view((1, -1))\n",
    "#         out = F.relu(self.linear1(embeds))\n",
    "#         out = self.linear2(out)\n",
    "#         log_probs = F.log_softmax(out, dim=1)\n",
    "#         return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4de7d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_REQUIRES_GRAD = False\n",
    "HIDDEN_CELLS = 25\n",
    "NUM_LAYERS = 1\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, pretrained_weights):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Creating embedding object from the pre-trained weights\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_weights)\n",
    "        self.embedding.weight.requires_grad = EMBEDDING_REQUIRES_GRAD\n",
    "        # Create a single LSTM since this is a Siamese Network and the weights are shared\n",
    "        self.lstm = nn.LSTM(input_size=EMBEDDING_DIMENSION, hidden_size=HIDDEN_CELLS, num_layers = NUM_LAYERS, batch_first = True)\n",
    "    \n",
    "    # Manhattan Distance Calculator\n",
    "    def exponent_neg_manhattan_distance(self, x1, x2):\n",
    "        return torch.exp(-torch.sum(torch.abs(x1 - x2), dim=0)).to(device)\n",
    "\n",
    "    def forward_once(self, x, input_lengths):\n",
    "      \n",
    "        # x is of the shape (batch_dim, sequence)\n",
    "        # e.g. x = [\n",
    "        #  [i1, i2, i3],\n",
    "        #  [j1, j2, j3, j4]\n",
    "        # ]\n",
    "        \n",
    "        # input_lengths is the list that contains the sequence lengths for each sequence\n",
    "        # e.g. input_lengths = [3, 4]\n",
    "        \n",
    "        # Reverse sequence lengths indices in decreasing order as per the requirement from PyTorch before Padding and Packing\n",
    "        sorted_indices = np.flipud(np.argsort(input_lengths))\n",
    "        input_lengths = np.flipud(np.sort(input_lengths))\n",
    "        input_lengths = input_lengths.copy() # https://github.com/facebookresearch/InferSent/issues/99\n",
    "        \n",
    "        # Reorder questions in the decreasing order of their lengths\n",
    "        ordered_questions = [torch.LongTensor(x[i]).to(device) for i in sorted_indices]\n",
    "        # Pad sequences with 0s to the max length sequence in the batch\n",
    "        ordered_questions = torch.nn.utils.rnn.pad_sequence(ordered_questions, batch_first=True)\n",
    "        # Retrieve Embeddings\n",
    "        embeddings = self.embedding(ordered_questions).to(device)\n",
    "        # Pack the padded sequences and pass it through LSTM\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embeddings, input_lengths, batch_first=True)\n",
    "        out, (hn, cn) = self.lstm(packed)\n",
    "        unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=int(input_lengths[0]))\n",
    "        \n",
    "        # The following step reorders the calculated activations to the original order in which questions were passed\n",
    "        result = torch.FloatTensor(unpacked.size())\n",
    "        for i, encoded_matrix in enumerate(unpacked):\n",
    "            result[sorted_indices[i]] = encoded_matrix\n",
    "        print(result.size())\n",
    "        return result\n",
    "\n",
    "    def forward(self, q1, q1_lengths, q2, q2_lengths):\n",
    "        output1 = self.forward_once(q1, q1_lengths)\n",
    "        output2 = self.forward_once(q2, q2_lengths)\n",
    "        similarity_score = torch.zeros(output1.size()[0]).to(device)\n",
    "        # Calculate Similarity Score between both questions in a single pair\n",
    "        for index in range(output1.size()[0]):\n",
    "            # Sequence lenghts are being used to index and retrieve the activations before the zero padding since they were not part of original question\n",
    "            q1 = output1[index, q1_lengths[index] - 1, :]\n",
    "            print('oh')\n",
    "            print(q1.size())\n",
    "            q2 = output2[index, q2_lengths[index] - 1, :]\n",
    "            print('ho')\n",
    "            print(q2.size())\n",
    "            similarity_score[index] = self.exponent_neg_manhattan_distance(q1, q2)\n",
    "        return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a07f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 19, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 22, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 19, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 19, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 19, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 19, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 22, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 24, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 19, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 22, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 22, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 22, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 8, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 17, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 18, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 14, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 23, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 15, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 16, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 25, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 9, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 23, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 7, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 11, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 10, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n",
      "torch.Size([1, 13, 25])\n",
      "torch.Size([1, 32, 25])\n",
      "oh\n",
      "torch.Size([25])\n",
      "ho\n",
      "torch.Size([25])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-399fd453d426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Run the forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0msimilarity_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq1_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq1_batch_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2_batch_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msimilarity_score\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ZW\\anaconda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-ee99b39179f0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, q1, q1_lengths, q2, q2_lengths)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ho'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0msimilarity_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexponent_neg_manhattan_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msimilarity_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-ee99b39179f0>\u001b[0m in \u001b[0;36mexponent_neg_manhattan_distance\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Manhattan Distance Calculator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexponent_neg_manhattan_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SiameseNetwork(weights).to(device)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "# Threshold 0.5. Since similarity score will be a value between 0 and 1, we will consider all question pair with values greater than threshold as Duplicate\n",
    "threshold = torch.Tensor([0.5]).to(device)\n",
    "\n",
    "# define hyperparameter\n",
    "num_epochs = 1\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001 )\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_history = []\n",
    "    model.train(True)\n",
    "    train_correct_total = 0\n",
    "    for i, (q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths, labels) in enumerate(train_loader):\n",
    "#         print(labels)\n",
    "        labels = torch.FloatTensor(labels).to(device)\n",
    "        \n",
    "        # Clear grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Run the forward pass\n",
    "        similarity_score = model(q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths)\n",
    "        predictions = (similarity_score > threshold).float() * 1\n",
    "        total = labels.size()[0]\n",
    "#         print(total)\n",
    "        correct = (predictions == labels).sum().item()\n",
    "        train_correct_total += correct\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = criterion(similarity_score, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            loss_history.append(loss.item())\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch + 1, num_epochs, i + 1, total_step, np.mean(loss_history), (train_correct_total / (i+1)) * 100))\n",
    "            \n",
    "    print('Training Loss: {:.4f}, Training Accuracy: {:.4f}'.format(np.mean(loss_history), (train_correct_total / len(train_indices)) * 100))\n",
    "    \n",
    "    model.train(False)\n",
    "    val_correct_total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths, labels) in enumerate(val_loader):\n",
    "\n",
    "            labels = torch.FloatTensor(labels).to(device)\n",
    "\n",
    "            similarity_score = model(q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths)\n",
    "            predictions = (similarity_score > threshold).float() * 1\n",
    "            total = labels.size()[0]\n",
    "            correct = (predictions == labels).sum().item()\n",
    "            val_correct_total += correct\n",
    "        \n",
    "        avg_acc_val =  val_correct_total * 100 / len(val_indices)\n",
    "        print ('Validation Set Size {}, Correct in Validation {}, Validation Accuracy {:.2f}%'.format(len(val_indices), val_correct_total, avg_acc_val))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19af364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7707f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
